{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343c24aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rakhat\\anaconda3\\envs\\irenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "import ir_measures\n",
    "from ir_measures import *\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "requests.packages.urllib3.disable_warnings() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71239a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rakhat\\anaconda3\\envs\\irenv\\lib\\site-packages\\elasticsearch\\_sync\\client\\__init__.py:394: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch([{'host' : 'localhost', 'port' : 9200, 'scheme' : 'https'}], basic_auth=(\"elastic\",\"X8w8*Kabqp+5d5ROVoYM\"), verify_certs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a315874",
   "metadata": {},
   "source": [
    "# Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6568ac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'en1kindex'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.create(index='en1kindex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cbcce8",
   "metadata": {},
   "source": [
    "# Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88743c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'properties' : {\n",
    "        'text_right' : {\n",
    "            'type' : 'text'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c10959",
   "metadata": {},
   "outputs": [],
   "source": [
    "settingsNoStemmer = {\n",
    "    'analysis' : {\n",
    "        'analyzer' : {\n",
    "            'default' : {\n",
    "                'tokenizer' : 'whitespace'\n",
    "            },\n",
    "            \"default_search\": {\n",
    "                'tokenizer' : 'whitespace'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987b038",
   "metadata": {},
   "source": [
    "# Index modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976f4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_index():\n",
    "    es.indices.delete(index='en1kindex')\n",
    "    es.indices.create(index='en1kindex', mappings=mappings, settings=settingsNoStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2cee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "recreate_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797ef7e",
   "metadata": {},
   "source": [
    "# Check Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4e4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_analyzer(analyzer, text):\n",
    "    body = analyzer\n",
    "    body['text'] = text\n",
    "    \n",
    "    tokens = es.indices.analyze(index='en1kindex', body=body)['tokens']\n",
    "    tokens = [token_info['token'] for token_info in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "207513a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'it was used in landing craft during world war ii and is used today in private boats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fd59f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rakhat\\AppData\\Local\\Temp\\ipykernel_14940\\1015729720.py:5: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  tokens = es.indices.analyze(index='en1kindex', body=body)['tokens']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'was',\n",
       " 'used',\n",
       " 'in',\n",
       " 'landing',\n",
       " 'craft',\n",
       " 'during',\n",
       " 'world',\n",
       " 'war',\n",
       " 'ii',\n",
       " 'and',\n",
       " 'is',\n",
       " 'used',\n",
       " 'today',\n",
       " 'in',\n",
       " 'private',\n",
       " 'boats']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = {\n",
    "    'analyzer': 'default'\n",
    "}\n",
    "\n",
    "check_analyzer(analyzer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24eb6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es_action(index, doc_id, document):\n",
    "    return {\n",
    "        '_index': index,\n",
    "        '_id': doc_id,\n",
    "        '_source': document\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e4904",
   "metadata": {},
   "source": [
    "# Index documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67514d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_actions_generator():\n",
    "    with open('documents.csv', 'r') as en1k:\n",
    "        documentReader = csv.DictReader(en1k)\n",
    "        for document in documentReader:\n",
    "            text_right = document['text_right']\n",
    "            docID = document[\"id_right\"]\n",
    "            doc = json.dumps({'text_right' : text_right})\n",
    "            yield create_es_action('en1kindex', docID, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25dedcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 16.379539012908936 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for ok, result in parallel_bulk(es, es_actions_generator()):\n",
    "    if not ok:\n",
    "        print(result)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed079f",
   "metadata": {},
   "source": [
    "# Perform Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf1cf14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    res = es.search(index='en1kindex', query=query, size=20, min_score=0)['hits']\n",
    "    finalRes = []\n",
    "    docInfo = {}\n",
    "    for hit in res['hits']:\n",
    "        finalRes.append(hit[\"_source\"][\"text_right\"])\n",
    "        docInfo[hit[\"_source\"][\"text_right\"]] = hit[\"_id\"]\n",
    "    return finalRes, docInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f995f",
   "metadata": {},
   "source": [
    "# Create query format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7087dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'bool': {\n",
    "        'should': [\n",
    "            {\n",
    "                'match': {\n",
    "                    'text_right': ''\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"match_all\": {}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0029ff2",
   "metadata": {},
   "source": [
    "# Copy queries from test folder and generate triples and query execution time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f2db814",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryToDocs = {}\n",
    "docInfo = {}\n",
    "queryInfo = {}\n",
    "\n",
    "with open('test/queries.csv', 'r') as qw:\n",
    "    queryReader = csv.DictReader(qw)\n",
    "    for q in queryReader:\n",
    "        text_left = q['text_left']\n",
    "        queryInfo[text_left] = q[\"id_left\"]\n",
    "        query['bool']['should'][0]['match']['text_right'] = text_left\n",
    "        queryToDocs[text_left], partialDocInfo = search(query)\n",
    "        docInfo.update(partialDocInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb529229",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L6-cos-v5', device='cuda')\n",
    "\n",
    "with open(\"ST.res\", \"w\") as run:\n",
    "    for qry, docs in queryToDocs.items():\n",
    "        \n",
    "        query_embedding = model.encode(qry, convert_to_tensor=True)\n",
    "        doc_embeddings = model.encode(docs, convert_to_tensor=True)\n",
    "\n",
    "        cos_scores = util.cos_sim(query_embedding, doc_embeddings)[0]\n",
    "        topResults = torch.topk(cos_scores, k=20)\n",
    "        \n",
    "        rank = 0\n",
    "        for score, idx in zip(topResults[0], topResults[1]):\n",
    "            run.write(str(queryInfo[qry]) + \" Q0 \" + str(docInfo[docs[idx]]) + \" \" + str(rank) + \" \" + str(float(score)) + \" ST\\n\")\n",
    "            rank += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27600f06",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352c8e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{AP@20: 0.16783148568225636,\n",
       " P@20: 0.14800000000000002,\n",
       " P@10: 0.21599999999999994}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = ir_measures.read_trec_qrels('test/qrels')\n",
    "run = ir_measures.read_trec_run('ST.res')\n",
    "ir_measures.calc_aggregate([P@10, P@20, MAP@20], qrels, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51366d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
